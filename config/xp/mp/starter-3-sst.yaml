# @package _global_

_entrypoint: train
_checkpoint: null
_max_epochs: 1600
_scheme: ${_sch.state}  # state-based or (lat, lon)-based multiprior
_sch:
  state:  # state-based multiprior
    source: contrib.multiprior
    weight:
      in_channel: ${datamodule.xrds_kw.patch_dims.time}
      out_channel: 1
      upsample_mode: bilinear
  latlon: # (lat, lon)-based multiprior
    source: contrib.multiprior.latlon
    weight:
      in_channel: 2
      out_channel: 1
      upsample_mode: bilinear

datamodule:
  _target_: ${_scheme.source}.MultiPriorDataModule
  input_da:
    _target_: ${_scheme.source}.load_data
    inp_path: ${path.input}
    gt_path: ${path.gt}
    oi_path: ${path.sst}
    oi_var: sst
    obs_var: five_nadirs
    train_domain: ${domain.train}
  domains:
    train:
      time: {_target_: builtins.slice, _args_: ['2013-02-24', '2013-09-30']}
    val:
      time: {_target_: builtins.slice, _args_: ['2012-12-15', '2013-02-24']}
    test:
      time: {_target_: builtins.slice,  _args_: ['2012-10-01', '2012-12-20']}
  xrds_kw:
    patch_dims: { time: 15, lat: 240, lon: 240}
    strides: { time: 1, lat: 200, lon: 200}
    domain_limits: ${domain.train}
  dl_kw: {batch_size: 4, num_workers: 1}
  aug_kw:
    aug_factor: 5

model:
  _target_: ${_scheme.source}.MultiPriorLitModel
  opt_fn:
    _target_: src.utils.cosanneal_lr_adam
    _partial_: true
    lr: 1e-3
    T_max: ${_max_epochs}
  rec_weight:
      _target_: src.utils.get_triang_time_wei
      patch_dims: ${datamodule.xrds_kw.patch_dims}
      crop: {time: 0, lat: 20, lon: 20}
      offset: 0
  solver:
    _target_: ${_scheme.source}.MultiPriorGradSolver
    n_step: 15
    lr_grad: 0.2
    prior_cost:
      _target_: contrib.multiprior.MultiPriorCost
      prior_costs:
      - _target_: src.models.BilinAEPriorCost
        dim_in: ${datamodule.xrds_kw.patch_dims.time}
        dim_hidden: 64
        downsamp: 2
      - _target_: src.models.BilinAEPriorCost
        dim_in: ${datamodule.xrds_kw.patch_dims.time}
        dim_hidden: 32
        downsamp: 2
      weight_mod_factory:
        - _target_: contrib.multiprior.WeightMod
          in_channel: ${_scheme.weight.in_channel}
          out_channel: ${_scheme.weight.out_channel}
          upsample_mode: ${_scheme.weight.upsample_mode}
          resize_factor: 10
        - _target_: contrib.multiprior.DeeperWeightMod
          in_channel: ${_scheme.weight.in_channel}
          mid_channel: 8
          out_channel: ${_scheme.weight.out_channel}
          upsample_mode: ${_scheme.weight.upsample_mode}
          resize_factor: 10

    obs_cost:
      _target_: src.models.BaseObsCost
    grad_mod:
      _target_: src.models.ConvLstmGradModel
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 96
  test_metrics: ${metrics.test_metrics}
  pre_metric_fn:
    _target_: xarray.Dataset.sel
    _partial_: true
    time: {_target_: builtins.slice, _args_: ['2012-10-22', '2012-12-02']}
    lat: ${domain.test.lat}
    lon: ${domain.test.lon}

metrics:
  nrmse_scores:
    _target_: src.utils.rmse_based_scores_from_ds
    _partial_: true
  psd_scores:
    _target_: src.utils.psd_based_scores_from_ds
    _partial_: true
  get0: {_target_: operator.itemgetter, _args_: [0]}
  get1: {_target_: operator.itemgetter, _args_: [1]}
  test_metrics:
    mu:
      _target_: src.utils.pipe
      _partial_: true
      fns: ['${metrics.nrmse_scores}', '${metrics.get0}']
    sig:
      _target_: src.utils.pipe
      _partial_: true
      fns: ['${metrics.nrmse_scores}', '${metrics.get1}']
    lx:
      _target_: src.utils.pipe
      _partial_: true
      fns: ['${metrics.psd_scores}', '${metrics.get0}']
    lt:
      _target_: src.utils.pipe
      _partial_: true
      fns: ['${metrics.psd_scores}', '${metrics.get1}']

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: false
  gradient_clip_val: 0.5
  accelerator: gpu
  # devices: 1
  logger:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ''
    version: ''
  max_epochs: ${_max_epochs}
  callbacks:
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 10
      filename: '{val_mse:.4f}-{epoch:03d}'

entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: "contrib.multiprior.${_entrypoint}"
    trainer: ${trainer}
    model: ${model}
    dm: ${datamodule}
    ckpt: ${_checkpoint}

defaults:
- /domain: gf
- /_LOCAL_path  # Must contain `path: {'input': ..., 'gt': ...}`
- _self_
